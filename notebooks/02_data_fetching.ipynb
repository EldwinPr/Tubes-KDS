{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04137d4a",
   "metadata": {},
   "source": [
    "Setup & Import Previous Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "574fa58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 22:32:51,096 - INFO - Starting data fetching notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREVIOUS EXPLORATION RESULTS:\n",
      "Total sequences available: 327\n",
      "Target species: Biston betularia\n",
      "Exploration date: 2025-05-31T22:16:22.668568\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import Config\n",
    "from utils import setup_logging, validate_sequence, save_checkpoint, clean_sequence\n",
    "\n",
    "# Import Biopython\n",
    "from Bio import Entrez, SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# Setup\n",
    "logger = setup_logging()\n",
    "Entrez.email = Config.NCBI_EMAIL\n",
    "logger.info(\"Starting data fetching notebook\")\n",
    "\n",
    "# Load previous exploration results\n",
    "with open('../data/processed/exploration_results.json', 'r') as f:\n",
    "    exploration_results = json.load(f)\n",
    "\n",
    "print(\"PREVIOUS EXPLORATION RESULTS:\")\n",
    "print(f\"Total sequences available: {exploration_results['total_sequences_available']}\")\n",
    "print(f\"Target species: {exploration_results['target_species']}\")\n",
    "print(f\"Exploration date: {exploration_results['exploration_date']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aab901",
   "metadata": {},
   "source": [
    "Advanced Search with Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae69116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: Biston betularia[Organism] AND COI[Gene] AND United Kingdom[Country] AND 400:800[SLEN] AND biomol_genomic[PROP]\n",
      "Searching for up to 20 sequences...\n",
      "Found 4 total sequences matching criteria\n",
      "Retrieved 4 sequence IDs for download\n",
      "\n",
      "UK-specific search results:\n",
      "Total UK sequences: 4\n",
      "IDs to download: 4\n"
     ]
    }
   ],
   "source": [
    "def search_ncbi_with_filters(species, gene, location=None, max_results=50):\n",
    "    \"\"\"\n",
    "    Search NCBI dengan filters geografis dan kualitas\n",
    "    \n",
    "    Args:\n",
    "        species (str): Target species\n",
    "        gene (str): Target gene\n",
    "        location (str): Geographic filter (optional)\n",
    "        max_results (int): Maximum results to return\n",
    "    \n",
    "    Returns:\n",
    "        list: List of sequence IDs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Build search term\n",
    "        search_terms = [\n",
    "            f\"{species}[Organism]\",\n",
    "            f\"{gene}[Gene]\"\n",
    "        ]\n",
    "        \n",
    "        # Add geographic filter if specified\n",
    "        if location:\n",
    "            search_terms.append(f\"{location}[Country]\")\n",
    "        \n",
    "        # Add quality filters\n",
    "        search_terms.extend([\n",
    "            \"400:800[SLEN]\",  # Sequence length between 400-800 bp\n",
    "            \"biomol_genomic[PROP]\"  # Genomic sequences only\n",
    "        ])\n",
    "        \n",
    "        search_query = \" AND \".join(search_terms)\n",
    "        \n",
    "        print(f\"Search query: {search_query}\")\n",
    "        print(f\"Searching for up to {max_results} sequences...\")\n",
    "        \n",
    "        # Perform search\n",
    "        handle = Entrez.esearch(\n",
    "            db=Config.NCBI_DATABASE,\n",
    "            term=search_query,\n",
    "            retmax=max_results,\n",
    "            sort=\"relevance\"\n",
    "        )\n",
    "        \n",
    "        search_results = Entrez.read(handle)\n",
    "        handle.close()\n",
    "        \n",
    "        id_list = search_results[\"IdList\"]\n",
    "        total_found = int(search_results[\"Count\"])\n",
    "        \n",
    "        print(f\"Found {total_found} total sequences matching criteria\")\n",
    "        print(f\"Retrieved {len(id_list)} sequence IDs for download\")\n",
    "        \n",
    "        return id_list, total_found\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Search failed: {e}\")\n",
    "        return [], 0\n",
    "\n",
    "# Search dengan filter UK\n",
    "uk_ids, uk_total = search_ncbi_with_filters(\n",
    "    species=Config.TARGET_SPECIES,\n",
    "    gene=Config.TARGET_GENE,\n",
    "    location=Config.TARGET_LOCATION,\n",
    "    max_results=Config.MAX_SEQUENCES_TEST\n",
    ")\n",
    "\n",
    "print(f\"\\nUK-specific search results:\")\n",
    "print(f\"Total UK sequences: {uk_total}\")\n",
    "print(f\"IDs to download: {len(uk_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3fb2d",
   "metadata": {},
   "source": [
    "Batch Download Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4499ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting UK sequence download...\n",
      "Downloading 4 sequences in batches of 5...\n",
      "Processing batch 1/1 (4 sequences)...\n",
      "  Added: KX043781.1\n",
      "  Added: KX071139.1\n",
      "  Added: KX044146.1\n",
      "  Added: KX043790.1\n",
      "\n",
      "Download complete!\n",
      "Successfully downloaded: 4 sequences\n",
      "Failed downloads: 0 sequences\n"
     ]
    }
   ],
   "source": [
    "def fetch_sequences_batch(id_list, batch_size=10, delay=1.0):\n",
    "    \"\"\"\n",
    "    Download sequences dalam batches untuk avoid rate limits\n",
    "    \n",
    "    Args:\n",
    "        id_list (list): List of sequence IDs\n",
    "        batch_size (int): Number of sequences per batch\n",
    "        delay (float): Delay between batches (seconds)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of SeqRecord objects\n",
    "    \"\"\"\n",
    "    all_records = []\n",
    "    failed_ids = []\n",
    "    \n",
    "    print(f\"Downloading {len(id_list)} sequences in batches of {batch_size}...\")\n",
    "    \n",
    "    for i in range(0, len(id_list), batch_size):\n",
    "        batch_ids = id_list[i:i+batch_size]\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        total_batches = (len(id_list) + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"Processing batch {batch_num}/{total_batches} ({len(batch_ids)} sequences)...\")\n",
    "        \n",
    "        try:\n",
    "            # Fetch batch\n",
    "            handle = Entrez.efetch(\n",
    "                db=Config.NCBI_DATABASE,\n",
    "                id=batch_ids,\n",
    "                rettype=\"gb\",\n",
    "                retmode=\"text\"\n",
    "            )\n",
    "            \n",
    "            # Parse records\n",
    "            batch_records = list(SeqIO.parse(handle, \"genbank\"))\n",
    "            handle.close()\n",
    "            \n",
    "            # Validate and add records\n",
    "            for record in batch_records:\n",
    "                if validate_sequence(str(record.seq)):\n",
    "                    all_records.append(record)\n",
    "                    print(f\"  Added: {record.id}\")\n",
    "                else:\n",
    "                    print(f\"  Skipped (invalid): {record.id}\")\n",
    "                    failed_ids.append(record.id)\n",
    "            \n",
    "            # Rate limiting delay\n",
    "            if i + batch_size < len(id_list):  # Don't delay after last batch\n",
    "                print(f\"  Waiting {delay}s before next batch...\")\n",
    "                time.sleep(delay)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Batch {batch_num} failed: {e}\")\n",
    "            failed_ids.extend(batch_ids)\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nDownload complete!\")\n",
    "    print(f\"Successfully downloaded: {len(all_records)} sequences\")\n",
    "    print(f\"Failed downloads: {len(failed_ids)} sequences\")\n",
    "    \n",
    "    return all_records, failed_ids\n",
    "\n",
    "# Download UK sequences\n",
    "print(\"Starting UK sequence download...\")\n",
    "uk_records, uk_failed = fetch_sequences_batch(uk_ids, batch_size=5, delay=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196463b7",
   "metadata": {},
   "source": [
    "Extract Comprehensive Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4beb4f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata from 4 records...\n",
      "Metadata extraction complete!\n",
      "\n",
      "UK METADATA SUMMARY:\n",
      "Records processed: 4\n",
      "Unique countries: 1\n",
      "Date range: 13-Jul-2007 to 29-Jun-2007\n"
     ]
    }
   ],
   "source": [
    "def extract_comprehensive_metadata(records):\n",
    "    \"\"\"\n",
    "    Extract detailed metadata dari GenBank records\n",
    "    \n",
    "    Args:\n",
    "        records (list): List of SeqRecord objects\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Comprehensive metadata\n",
    "    \"\"\"\n",
    "    metadata_list = []\n",
    "    \n",
    "    print(f\"Extracting metadata from {len(records)} records...\")\n",
    "    \n",
    "    for i, record in enumerate(records):\n",
    "        metadata = {\n",
    "            'accession_id': record.id,\n",
    "            'accession_version': record.id,\n",
    "            'description': record.description,\n",
    "            'organism': record.annotations.get('organism', 'Unknown'),\n",
    "            'sequence_length': len(record.seq),\n",
    "            'sequence': str(record.seq),\n",
    "            'date_added': record.annotations.get('date', 'Unknown'),\n",
    "            'keywords': ','.join(record.annotations.get('keywords', [])),\n",
    "            'source': record.annotations.get('source', 'Unknown')\n",
    "        }\n",
    "        \n",
    "        # Extract from source feature\n",
    "        for feature in record.features:\n",
    "            if feature.type == \"source\":\n",
    "                qualifiers = feature.qualifiers\n",
    "                \n",
    "                # Geographic information\n",
    "                metadata['country'] = qualifiers.get('country', ['Unknown'])[0]\n",
    "                metadata['lat_lon'] = qualifiers.get('lat_lon', ['Unknown'])[0]\n",
    "                \n",
    "                # Collection information\n",
    "                metadata['collection_date'] = qualifiers.get('collection_date', ['Unknown'])[0]\n",
    "                metadata['collected_by'] = qualifiers.get('collected_by', ['Unknown'])[0]\n",
    "                metadata['identified_by'] = qualifiers.get('identified_by', ['Unknown'])[0]\n",
    "                \n",
    "                # Specimen information\n",
    "                metadata['specimen_voucher'] = qualifiers.get('specimen_voucher', ['Unknown'])[0]\n",
    "                metadata['isolate'] = qualifiers.get('isolate', ['Unknown'])[0]\n",
    "                \n",
    "                # Additional fields\n",
    "                metadata['sex'] = qualifiers.get('sex', ['Unknown'])[0]\n",
    "                metadata['life_stage'] = qualifiers.get('dev_stage', ['Unknown'])[0]\n",
    "                metadata['tissue_type'] = qualifiers.get('tissue_type', ['Unknown'])[0]\n",
    "                \n",
    "                break\n",
    "        \n",
    "        # Sequence composition analysis\n",
    "        seq_str = str(record.seq).upper()\n",
    "        metadata['gc_content'] = round((seq_str.count('G') + seq_str.count('C')) / len(seq_str) * 100, 2)\n",
    "        metadata['n_count'] = seq_str.count('N')\n",
    "        metadata['ambiguous_bases'] = sum(1 for char in seq_str if char in 'RYSWKMBDHV')\n",
    "        \n",
    "        # Quality metrics\n",
    "        metadata['sequence_quality'] = 'Valid' if validate_sequence(seq_str) else 'Invalid'\n",
    "        \n",
    "        metadata_list.append(metadata)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(records)} records...\")\n",
    "    \n",
    "    df = pd.DataFrame(metadata_list)\n",
    "    print(f\"Metadata extraction complete!\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Extract metadata from UK records\n",
    "if uk_records:\n",
    "    uk_metadata_df = extract_comprehensive_metadata(uk_records)\n",
    "    print(f\"\\nUK METADATA SUMMARY:\")\n",
    "    print(f\"Records processed: {len(uk_metadata_df)}\")\n",
    "    print(f\"Unique countries: {uk_metadata_df['country'].nunique()}\")\n",
    "    print(f\"Date range: {uk_metadata_df['collection_date'].min()} to {uk_metadata_df['collection_date'].max()}\")\n",
    "else:\n",
    "    print(\"No UK records to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f995b8c",
   "metadata": {},
   "source": [
    "Geographic Analysis & Filterin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416f68e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOGRAPHIC DISTRIBUTION ANALYSIS:\n",
      "==================================================\n",
      "\n",
      "Country distribution:\n",
      "  Unknown: 4 sequences\n",
      "\n",
      "Coordinate data:\n",
      "  Records with coordinates: 3\n",
      "  Records without coordinates: 1\n",
      "  Sample coordinates:\n",
      "    51.4328 N 0.94377 W\n",
      "    51.62 N 0.04 E\n",
      "    52.548 N 0.881 E\n",
      "\n",
      "Temporal distribution:\n",
      "  Records with dates: 4\n",
      "  Date range: 13-Jul-2007 to 29-Jun-2007\n",
      "\n",
      "FILTERED UK DATASET:\n",
      "Original records: 4\n",
      "High-quality UK records: 0\n"
     ]
    }
   ],
   "source": [
    "def analyze_geographic_distribution(df):\n",
    "    \"\"\"\n",
    "    Analyze geographic distribution of sequences\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(\"GEOGRAPHIC DISTRIBUTION ANALYSIS:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Country distribution\n",
    "    country_counts = df['country'].value_counts()\n",
    "    print(f\"\\nCountry distribution:\")\n",
    "    for country, count in country_counts.head(10).items():\n",
    "        print(f\"  {country}: {count} sequences\")\n",
    "    \n",
    "    # Coordinates analysis\n",
    "    valid_coords = df[df['lat_lon'] != 'Unknown']['lat_lon']\n",
    "    print(f\"\\nCoordinate data:\")\n",
    "    print(f\"  Records with coordinates: {len(valid_coords)}\")\n",
    "    print(f\"  Records without coordinates: {len(df) - len(valid_coords)}\")\n",
    "    \n",
    "    if len(valid_coords) > 0:\n",
    "        print(f\"  Sample coordinates:\")\n",
    "        for coord in valid_coords.head(5):\n",
    "            print(f\"    {coord}\")\n",
    "    \n",
    "    # Collection date analysis\n",
    "    valid_dates = df[df['collection_date'] != 'Unknown']['collection_date']\n",
    "    print(f\"\\nTemporal distribution:\")\n",
    "    print(f\"  Records with dates: {len(valid_dates)}\")\n",
    "    print(f\"  Date range: {valid_dates.min()} to {valid_dates.max()}\" if len(valid_dates) > 0 else \"  No valid dates\")\n",
    "    \n",
    "    return country_counts\n",
    "\n",
    "# Analyze UK data\n",
    "if 'uk_metadata_df' in locals() and not uk_metadata_df.empty:\n",
    "    uk_geo_analysis = analyze_geographic_distribution(uk_metadata_df)\n",
    "    \n",
    "    # Filter for high-quality UK records\n",
    "    uk_filtered = uk_metadata_df[\n",
    "        (uk_metadata_df['sequence_quality'] == 'Valid') &\n",
    "        (uk_metadata_df['country'].str.contains('United Kingdom|UK|England|Scotland|Wales', na=False, case=False))\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"\\nFILTERED UK DATASET:\")\n",
    "    print(f\"Original records: {len(uk_metadata_df)}\")\n",
    "    print(f\"High-quality UK records: {len(uk_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc015489",
   "metadata": {},
   "source": [
    "Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f919be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw sequences saved: ../data/raw/biston_betularia_uk_raw_20250531.fasta\n",
      "Metadata saved: ../data/processed/biston_betularia_uk_metadata_20250531.csv\n",
      "\n",
      "Exploration results updated\n"
     ]
    }
   ],
   "source": [
    "if uk_records:\n",
    "    # Save sequences in FASTA format\n",
    "    fasta_filename = f\"../data/raw/biston_betularia_uk_raw_{datetime.now().strftime('%Y%m%d')}.fasta\"\n",
    "    SeqIO.write(uk_records, fasta_filename, \"fasta\")\n",
    "    print(f\"Raw sequences saved: {fasta_filename}\")\n",
    "    \n",
    "    # Save comprehensive metadata\n",
    "    metadata_filename = f\"../data/processed/biston_betularia_uk_metadata_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "    uk_metadata_df.to_csv(metadata_filename, index=False)\n",
    "    print(f\"Metadata saved: {metadata_filename}\")\n",
    "    \n",
    "    # Save filtered high-quality data\n",
    "    if 'uk_filtered' in locals() and not uk_filtered.empty:\n",
    "        filtered_filename = f\"../data/processed/biston_betularia_uk_filtered_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "        uk_filtered.to_csv(filtered_filename, index=False)\n",
    "        print(f\"Filtered data saved: {filtered_filename}\")\n",
    "    \n",
    "    # Update exploration results\n",
    "    exploration_results.update({\n",
    "        'uk_download_date': datetime.now().isoformat(),\n",
    "        'uk_sequences_downloaded': len(uk_records),\n",
    "        'uk_sequences_failed': len(uk_failed),\n",
    "        'uk_metadata_records': len(uk_metadata_df),\n",
    "        'uk_filtered_records': len(uk_filtered) if 'uk_filtered' in locals() else 0\n",
    "    })\n",
    "    \n",
    "    with open('../data/processed/exploration_results.json', 'w') as f:\n",
    "        json.dump(exploration_results, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nExploration results updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18eda1a",
   "metadata": {},
   "source": [
    "Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d66d7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA FETCHING SUMMARY\n",
      "============================================================\n",
      "Search parameters:\n",
      "  Target species: Biston betularia\n",
      "  Target gene: COI\n",
      "  Geographic filter: United Kingdom\n",
      "  Sequence length: 400-800 bp\n",
      "\n",
      "Download results:\n",
      "  Total sequences found: 4\n",
      "  Sequences downloaded: 4\n",
      "  Failed downloads: 0\n",
      "  Success rate: 100.0%\n",
      "\n",
      "Data quality:\n",
      "  Valid sequences: 4\n",
      "\n",
      "Sequence statistics:\n",
      "  Mean length: 630.5 bp\n",
      "  Length range: 597-658 bp\n",
      "  Mean GC content: 30.3%\n"
     ]
    }
   ],
   "source": [
    "if 'uk_metadata_df' in locals() and not uk_metadata_df.empty:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DATA FETCHING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"Search parameters:\")\n",
    "    print(f\"  Target species: {Config.TARGET_SPECIES}\")\n",
    "    print(f\"  Target gene: {Config.TARGET_GENE}\")\n",
    "    print(f\"  Geographic filter: {Config.TARGET_LOCATION}\")\n",
    "    print(f\"  Sequence length: {Config.MIN_SEQUENCE_LENGTH}-{Config.MAX_SEQUENCE_LENGTH} bp\")\n",
    "    \n",
    "    print(f\"\\nDownload results:\")\n",
    "    print(f\"  Total sequences found: {uk_total}\")\n",
    "    print(f\"  Sequences downloaded: {len(uk_records)}\")\n",
    "    print(f\"  Failed downloads: {len(uk_failed)}\")\n",
    "    print(f\"  Success rate: {len(uk_records)/(len(uk_records)+len(uk_failed))*100:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nData quality:\")\n",
    "    quality_counts = uk_metadata_df['sequence_quality'].value_counts()\n",
    "    for quality, count in quality_counts.items():\n",
    "        print(f\"  {quality} sequences: {count}\")\n",
    "    \n",
    "    print(f\"\\nSequence statistics:\")\n",
    "    print(f\"  Mean length: {uk_metadata_df['sequence_length'].mean():.1f} bp\")\n",
    "    print(f\"  Length range: {uk_metadata_df['sequence_length'].min()}-{uk_metadata_df['sequence_length'].max()} bp\")\n",
    "    print(f\"  Mean GC content: {uk_metadata_df['gc_content'].mean():.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"No data downloaded - check NCBI connection and search parameters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
