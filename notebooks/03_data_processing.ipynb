{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db4daffd",
   "metadata": {},
   "source": [
    "Setup & Load Previous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6157e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 13:21:22,584 - INFO - Starting complete data processing notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous results loaded successfully\n",
      "Error: No metadata files found. Please run Notebook 2 first.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import Config\n",
    "from utils import setup_logging, validate_sequence, clean_sequence, save_checkpoint\n",
    "\n",
    "# Import Biopython for sequence analysis\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "# Alternative GC content calculation\n",
    "def calculate_gc_content(sequence):\n",
    "    \"\"\"Calculate GC content without Bio.SeqUtils\"\"\"\n",
    "    if not sequence:\n",
    "        return 0.0\n",
    "    seq_upper = sequence.upper()\n",
    "    gc_count = seq_upper.count('G') + seq_upper.count('C')\n",
    "    return (gc_count / len(sequence)) * 100 if len(sequence) > 0 else 0.0\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging()\n",
    "logger.info(\"Starting complete data processing notebook\")\n",
    "\n",
    "# Load previous results\n",
    "try:\n",
    "    with open('../data/processed/exploration_results.json', 'r') as f:\n",
    "        exploration_results = json.load(f)\n",
    "    print(\"Previous results loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: Previous exploration results not found\")\n",
    "    exploration_results = {}\n",
    "\n",
    "# Find and load the most recent metadata file\n",
    "import glob\n",
    "metadata_files = glob.glob('../data/processed/biston_betularia_global_enhanced_*.csv')\n",
    "if metadata_files:\n",
    "    latest_metadata_file = max(metadata_files)\n",
    "    df_original = pd.read_csv(latest_metadata_file)\n",
    "    print(f\"Loaded metadata: {latest_metadata_file}\")\n",
    "    print(f\"Records loaded: {len(df_original)}\")\n",
    "    print(f\"Columns: {list(df_original.columns)}\")\n",
    "else:\n",
    "    print(\"Error: No metadata files found. Please run Notebook 2 first.\")\n",
    "    df_original = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273de1e",
   "metadata": {},
   "source": [
    "QUALITY CONTROL FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d7d99313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_sequence_qc(df):\n",
    "    \"\"\"Comprehensive quality control untuk sequences\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to process\")\n",
    "        return df, {}\n",
    "    \n",
    "    initial_count = len(df)\n",
    "    qc_stats = {\n",
    "        'initial_sequences': initial_count,\n",
    "        'removed_duplicates': 0,\n",
    "        'removed_short': 0,\n",
    "        'removed_long': 0,\n",
    "        'removed_invalid_chars': 0,\n",
    "        'removed_high_ambiguous': 0,\n",
    "        'final_sequences': 0\n",
    "    }\n",
    "    \n",
    "    print(\"SEQUENCE QUALITY CONTROL\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # 1. Remove duplicates based on sequence\n",
    "    print(f\"1. Checking for duplicate sequences...\")\n",
    "    before_dedup = len(df)\n",
    "    df_clean = df.drop_duplicates(subset=['sequence'], keep='first').copy()\n",
    "    qc_stats['removed_duplicates'] = before_dedup - len(df_clean)\n",
    "    print(f\"   Removed {qc_stats['removed_duplicates']} duplicate sequences\")\n",
    "    \n",
    "    # 2. Length filtering\n",
    "    print(f\"2. Filtering by sequence length ({Config.MIN_SEQUENCE_LENGTH}-{Config.MAX_SEQUENCE_LENGTH} bp)...\")\n",
    "    before_length = len(df_clean)\n",
    "    df_clean = df_clean[\n",
    "        (df_clean['sequence_length'] >= Config.MIN_SEQUENCE_LENGTH) &\n",
    "        (df_clean['sequence_length'] <= Config.MAX_SEQUENCE_LENGTH)\n",
    "    ].copy()\n",
    "    qc_stats['removed_short'] = before_length - len(df_clean)\n",
    "    print(f\"   Removed {qc_stats['removed_short']} sequences outside length range\")\n",
    "    \n",
    "    # 3. Clean sequences and check for invalid characters\n",
    "    print(f\"3. Cleaning sequences and removing invalid characters...\")\n",
    "    def check_and_clean_sequence(seq):\n",
    "        cleaned = clean_sequence(seq)\n",
    "        valid_chars = set('ATGCNRYSWKMBDHV')\n",
    "        return cleaned if set(cleaned.upper()).issubset(valid_chars) else None\n",
    "    \n",
    "    before_clean = len(df_clean)\n",
    "    df_clean['sequence_cleaned'] = df_clean['sequence'].apply(check_and_clean_sequence)\n",
    "    df_clean = df_clean.dropna(subset=['sequence_cleaned']).copy()\n",
    "    qc_stats['removed_invalid_chars'] = before_clean - len(df_clean)\n",
    "    print(f\"   Removed {qc_stats['removed_invalid_chars']} sequences with invalid characters\")\n",
    "    \n",
    "    # 4. Remove sequences with too many ambiguous bases\n",
    "    print(f\"4. Filtering sequences with >10% ambiguous bases...\")\n",
    "    def calculate_ambiguous_percentage(seq):\n",
    "        ambiguous_count = sum(1 for char in seq.upper() if char in 'NRYSWKMBDHV')\n",
    "        return ambiguous_count / len(seq) if len(seq) > 0 else 1.0\n",
    "    \n",
    "    before_ambiguous = len(df_clean)\n",
    "    df_clean['ambiguous_percentage'] = df_clean['sequence_cleaned'].apply(calculate_ambiguous_percentage)\n",
    "    df_clean = df_clean[df_clean['ambiguous_percentage'] <= 0.1].copy()\n",
    "    qc_stats['removed_high_ambiguous'] = before_ambiguous - len(df_clean)\n",
    "    print(f\"   Removed {qc_stats['removed_high_ambiguous']} sequences with >10% ambiguous bases\")\n",
    "    \n",
    "    # 5. Update sequence column with cleaned version\n",
    "    df_clean['sequence'] = df_clean['sequence_cleaned']\n",
    "    df_clean['sequence_length'] = df_clean['sequence'].str.len()\n",
    "    \n",
    "    qc_stats['final_sequences'] = len(df_clean)\n",
    "    \n",
    "    print(f\"\\nQUALITY CONTROL SUMMARY:\")\n",
    "    print(f\"Initial sequences: {qc_stats['initial_sequences']}\")\n",
    "    print(f\"Final sequences: {qc_stats['final_sequences']}\")\n",
    "    print(f\"Retention rate: {qc_stats['final_sequences']/qc_stats['initial_sequences']*100:.1f}%\")\n",
    "    \n",
    "    return df_clean, qc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f79906",
   "metadata": {},
   "source": [
    "DIVERSITY ANALYSIS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2f8eb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sequence_diversity(df):\n",
    "    \"\"\"Analyze genetic diversity dalam dataset\"\"\"\n",
    "    if df.empty:\n",
    "        return {}\n",
    "    \n",
    "    print(\"\\nSEQUENCE DIVERSITY ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    sequences = df['sequence'].tolist()\n",
    "    diversity_stats = {}\n",
    "    \n",
    "    # 1. Basic statistics\n",
    "    diversity_stats['total_sequences'] = len(sequences)\n",
    "    diversity_stats['unique_sequences'] = len(set(sequences))\n",
    "    diversity_stats['sequence_identity'] = diversity_stats['unique_sequences'] / diversity_stats['total_sequences']\n",
    "    \n",
    "    print(f\"Total sequences: {diversity_stats['total_sequences']}\")\n",
    "    print(f\"Unique sequences: {diversity_stats['unique_sequences']}\")\n",
    "    print(f\"Sequence diversity: {diversity_stats['sequence_identity']:.3f}\")\n",
    "    \n",
    "    # 2. Length distribution\n",
    "    lengths = df['sequence_length'].tolist()\n",
    "    diversity_stats['mean_length'] = np.mean(lengths)\n",
    "    diversity_stats['length_std'] = np.std(lengths)\n",
    "    diversity_stats['min_length'] = min(lengths)\n",
    "    diversity_stats['max_length'] = max(lengths)\n",
    "    \n",
    "    print(f\"\\nLength statistics:\")\n",
    "    print(f\"Mean length: {diversity_stats['mean_length']:.1f} ± {diversity_stats['length_std']:.1f} bp\")\n",
    "    print(f\"Length range: {diversity_stats['min_length']}-{diversity_stats['max_length']} bp\")\n",
    "    \n",
    "    # 3. GC content analysis\n",
    "    gc_contents = [calculate_gc_content(seq) for seq in sequences]\n",
    "    diversity_stats['mean_gc'] = np.mean(gc_contents)\n",
    "    diversity_stats['gc_std'] = np.std(gc_contents)\n",
    "    diversity_stats['min_gc'] = min(gc_contents)\n",
    "    diversity_stats['max_gc'] = max(gc_contents)\n",
    "    \n",
    "    print(f\"\\nGC content statistics:\")\n",
    "    print(f\"Mean GC content: {diversity_stats['mean_gc']:.1f} ± {diversity_stats['gc_std']:.1f}%\")\n",
    "    print(f\"GC range: {diversity_stats['min_gc']:.1f}-{diversity_stats['max_gc']:.1f}%\")\n",
    "    \n",
    "    # 4. Nucleotide composition\n",
    "    all_sequence = ''.join(sequences).upper()\n",
    "    total_bases = len(all_sequence)\n",
    "    base_counts = Counter(all_sequence)\n",
    "    \n",
    "    print(f\"\\nNucleotide composition:\")\n",
    "    for base in ['A', 'T', 'G', 'C']:\n",
    "        count = base_counts.get(base, 0)\n",
    "        percentage = count / total_bases * 100 if total_bases > 0 else 0\n",
    "        print(f\"{base}: {count:,} ({percentage:.1f}%)\")\n",
    "        diversity_stats[f'{base.lower()}_percentage'] = percentage\n",
    "    \n",
    "    return diversity_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ec01e",
   "metadata": {},
   "source": [
    "HAPLOTYPE IDENTIFICATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "254347b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_haplotypes_simple(df, similarity_threshold=0.97):\n",
    "    \"\"\"Simple haplotype identification\"\"\"\n",
    "    if df.empty:\n",
    "        return df, {}, []\n",
    "    \n",
    "    print(\"\\nHAPLOTYPE IDENTIFICATION\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Using similarity threshold: {similarity_threshold}\")\n",
    "    \n",
    "    sequences = df['sequence'].tolist()\n",
    "    unique_sequences = list(set(sequences))\n",
    "    \n",
    "    print(f\"Total sequences: {len(sequences)}\")\n",
    "    print(f\"Unique sequences: {len(unique_sequences)}\")\n",
    "    \n",
    "    # Simple clustering berdasarkan exact matches\n",
    "    haplotype_groups = []\n",
    "    sequence_to_haplotype = {}\n",
    "    \n",
    "    # Start dengan exact matches\n",
    "    sequence_counts = Counter(sequences)\n",
    "    haplotype_id = 1\n",
    "    \n",
    "    for seq, count in sequence_counts.most_common():\n",
    "        if seq not in sequence_to_haplotype:\n",
    "            haplotype_name = f\"Hap_{haplotype_id:03d}\"\n",
    "            sequence_to_haplotype[seq] = haplotype_name\n",
    "            haplotype_groups.append({\n",
    "                'haplotype_id': haplotype_name,\n",
    "                'representative_sequence': seq,\n",
    "                'sequence_count': count,\n",
    "                'frequency': count / len(sequences)\n",
    "            })\n",
    "            haplotype_id += 1\n",
    "    \n",
    "    # Assign haplotypes to dataframe\n",
    "    df_haplotypes = df.copy()\n",
    "    df_haplotypes['haplotype_id'] = df_haplotypes['sequence'].map(sequence_to_haplotype)\n",
    "    \n",
    "    # Calculate haplotype statistics\n",
    "    haplotype_stats = {\n",
    "        'total_haplotypes': len(haplotype_groups),\n",
    "        'most_common_haplotype': haplotype_groups[0]['haplotype_id'] if haplotype_groups else None,\n",
    "        'most_common_frequency': haplotype_groups[0]['frequency'] if haplotype_groups else 0,\n",
    "        'singleton_haplotypes': sum(1 for h in haplotype_groups if h['sequence_count'] == 1),\n",
    "        'haplotype_diversity': len(haplotype_groups) / len(sequences) if len(sequences) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nHaplotype identification results:\")\n",
    "    print(f\"Total haplotypes identified: {haplotype_stats['total_haplotypes']}\")\n",
    "    print(f\"Most common haplotype: {haplotype_stats['most_common_haplotype']} ({haplotype_stats['most_common_frequency']:.3f})\")\n",
    "    print(f\"Singleton haplotypes: {haplotype_stats['singleton_haplotypes']}\")\n",
    "    print(f\"Haplotype diversity: {haplotype_stats['haplotype_diversity']:.3f}\")\n",
    "    \n",
    "    # Print top 10 haplotypes\n",
    "    print(f\"\\nTop 10 most common haplotypes:\")\n",
    "    for i, hap in enumerate(haplotype_groups[:10]):\n",
    "        print(f\"{i+1:2d}. {hap['haplotype_id']}: {hap['sequence_count']:3d} sequences ({hap['frequency']:.3f})\")\n",
    "    \n",
    "    return df_haplotypes, haplotype_stats, haplotype_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f737c",
   "metadata": {},
   "source": [
    "EXPORT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ebaa3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_final_dataset(df, haplotype_groups, qc_stats, diversity_stats, haplotype_stats):\n",
    "    \"\"\"Export final processed dataset untuk ABM simulation\"\"\"\n",
    "    if df.empty:\n",
    "        print(\"No data to export\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Create final directory if it doesn't exist\n",
    "    os.makedirs(\"../data/final\", exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # 1. Export main dataset\n",
    "    final_dataset_file = f\"../data/final/biston_betularia_final_dataset_{timestamp}.csv\"\n",
    "    \n",
    "    # Select important columns untuk ABM\n",
    "    export_columns = [\n",
    "        'accession_id', 'haplotype_id', 'sequence', 'sequence_length',\n",
    "        'country', 'collection_date', 'lat_lon', 'collected_by',\n",
    "        'organism', 'description'\n",
    "    ]\n",
    "    \n",
    "    # Only include columns that exist\n",
    "    available_columns = [col for col in export_columns if col in df.columns]\n",
    "    df_export = df[available_columns].copy()\n",
    "    \n",
    "    # Add GC content\n",
    "    df_export['gc_content'] = df_export['sequence'].apply(calculate_gc_content)\n",
    "    \n",
    "    df_export.to_csv(final_dataset_file, index=False)\n",
    "    print(f\"\\nFinal dataset exported: {final_dataset_file}\")\n",
    "    print(f\"Records: {len(df_export)}\")\n",
    "    print(f\"Columns: {list(df_export.columns)}\")\n",
    "    \n",
    "    # 2. Export haplotype summary\n",
    "    haplotype_summary_file = f\"../data/final/haplotype_summary_{timestamp}.csv\"\n",
    "    haplotype_df = pd.DataFrame(haplotype_groups)\n",
    "    haplotype_df.to_csv(haplotype_summary_file, index=False)\n",
    "    print(f\"Haplotype summary exported: {haplotype_summary_file}\")\n",
    "    \n",
    "    # 3. Export analysis summary\n",
    "    analysis_summary = {\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'input_sequences': qc_stats.get('initial_sequences', 0),\n",
    "        'final_sequences': qc_stats.get('final_sequences', 0),\n",
    "        'retention_rate': qc_stats.get('final_sequences', 0) / qc_stats.get('initial_sequences', 1),\n",
    "        'unique_sequences': diversity_stats.get('unique_sequences', 0),\n",
    "        'total_haplotypes': haplotype_stats.get('total_haplotypes', 0),\n",
    "        'haplotype_diversity': haplotype_stats.get('haplotype_diversity', 0),\n",
    "        'mean_sequence_length': diversity_stats.get('mean_length', 0),\n",
    "        'mean_gc_content': diversity_stats.get('mean_gc', 0),\n",
    "        'quality_control': qc_stats,\n",
    "        'diversity_analysis': diversity_stats,\n",
    "        'haplotype_analysis': haplotype_stats\n",
    "    }\n",
    "    \n",
    "    summary_file = f\"../data/final/analysis_summary_{timestamp}.json\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(analysis_summary, f, indent=2)\n",
    "    print(f\"Analysis summary exported: {summary_file}\")\n",
    "    \n",
    "    return final_dataset_file, haplotype_summary_file, summary_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decffdaf",
   "metadata": {},
   "source": [
    "VisualizationMAIN PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "966966c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_processing():\n",
    "    \"\"\"Run the complete processing pipeline\"\"\"\n",
    "    \n",
    "    if df_original.empty:\n",
    "        print(\"ERROR: No input data available. Please run Notebook 2 first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Starting processing pipeline with {len(df_original)} sequences\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Quality Control\n",
    "    df_clean, qc_statistics = comprehensive_sequence_qc(df_original)\n",
    "    \n",
    "    if df_clean.empty:\n",
    "        print(\"ERROR: No sequences passed quality control\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Diversity Analysis\n",
    "    diversity_analysis = analyze_sequence_diversity(df_clean)\n",
    "    \n",
    "    # Step 3: Haplotype Identification\n",
    "    df_haplotypes, haplotype_statistics, haplotype_groups = identify_haplotypes_simple(\n",
    "        df_clean, \n",
    "        similarity_threshold=Config.SIMILARITY_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    # Step 4: Export Results\n",
    "    final_files = export_final_dataset(\n",
    "        df_haplotypes, \n",
    "        haplotype_groups, \n",
    "        qc_statistics, \n",
    "        diversity_analysis, \n",
    "        haplotype_statistics\n",
    "    )\n",
    "    \n",
    "    # Step 5: Final Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DATA PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Processing completed successfully!\")\n",
    "    print(f\"Final dataset ready for ABM simulation\")\n",
    "    \n",
    "    print(f\"\\nFINAL RESULTS SUMMARY:\")\n",
    "    print(f\"Total sequences processed: {qc_statistics['final_sequences']}\")\n",
    "    print(f\"Unique haplotypes identified: {haplotype_statistics['total_haplotypes']}\")\n",
    "    print(f\"Haplotype diversity: {haplotype_statistics['haplotype_diversity']:.3f}\")\n",
    "    print(f\"Mean sequence length: {diversity_analysis['mean_length']:.1f} bp\")\n",
    "    print(f\"Mean GC content: {diversity_analysis['mean_gc']:.1f}%\")\n",
    "    print(f\"Data retention rate: {qc_statistics['final_sequences']/qc_statistics['initial_sequences']*100:.1f}%\")\n",
    "    \n",
    "    return df_haplotypes, haplotype_groups, qc_statistics, diversity_analysis, haplotype_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf17e5f",
   "metadata": {},
   "source": [
    "RUN THE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fbde9035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No input data available - please run Notebook 2 first to fetch data from NCBI\n"
     ]
    }
   ],
   "source": [
    "if not df_original.empty:\n",
    "    results = run_complete_processing()\n",
    "    if results:\n",
    "        df_haplotypes, haplotype_groups, qc_statistics, diversity_analysis, haplotype_statistics = results\n",
    "        print(\"\\nAll variables successfully created and available for further analysis!\")\n",
    "    else:\n",
    "        print(\"Processing failed - check input data and error messages above\")\n",
    "else:\n",
    "    print(\"No input data available - please run Notebook 2 first to fetch data from NCBI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
