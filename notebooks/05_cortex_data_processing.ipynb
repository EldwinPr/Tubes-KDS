{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ad98d2",
   "metadata": {},
   "source": [
    "SETUP & IMPORT PREVIOUS RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5063ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 11:00:53,884 - INFO - Starting cortex data processing notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORTEX GENE DATA PROCESSING\n",
      "==================================================\n",
      "Target: Biston betularia cortex gene\n",
      "Purpose: Clean data for ABM simulation\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import Config\n",
    "from utils import setup_logging, validate_sequence, clean_sequence, save_checkpoint\n",
    "\n",
    "# Import Biopython\n",
    "from Bio import Entrez, SeqIO\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging()\n",
    "Entrez.email = Config.NCBI_EMAIL\n",
    "logger.info(\"Starting cortex data processing notebook\")\n",
    "\n",
    "print(\"CORTEX GENE DATA PROCESSING\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Target: {Config.TARGET_SPECIES} cortex gene\")\n",
    "print(f\"Purpose: Clean data for ABM simulation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a992f58",
   "metadata": {},
   "source": [
    "CORTEX GENE CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffaf85aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cortex processing configuration:\n",
      "Length range: 200-3000 bp\n",
      "Max sequences: 100\n",
      "Max ambiguous: 15.0%\n"
     ]
    }
   ],
   "source": [
    "class CortexConfig:\n",
    "    \"\"\"Configuration for cortex gene processing\"\"\"\n",
    "    \n",
    "    # Search parameters\n",
    "    GENE_NAME = \"cortex\"\n",
    "    MIN_LENGTH = 200\n",
    "    MAX_LENGTH = 3000\n",
    "    MAX_SEQUENCES = 100\n",
    "    BATCH_SIZE = 5\n",
    "    \n",
    "    # Quality thresholds (more lenient than COI)\n",
    "    MAX_AMBIGUOUS_PERCENTAGE = 15.0\n",
    "    SIMILARITY_THRESHOLD = 0.97\n",
    "    \n",
    "print(f\"Cortex processing configuration:\")\n",
    "print(f\"Length range: {CortexConfig.MIN_LENGTH}-{CortexConfig.MAX_LENGTH} bp\")\n",
    "print(f\"Max sequences: {CortexConfig.MAX_SEQUENCES}\")\n",
    "print(f\"Max ambiguous: {CortexConfig.MAX_AMBIGUOUS_PERCENTAGE}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbbb1d4",
   "metadata": {},
   "source": [
    "NCBI SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21986aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for cortex sequences...\n",
      "  Searching: Biston betularia[Organism] AND cortex[Gene]\n",
      "    Found: 0 retrieved / 0 total\n",
      "  Searching: Biston betularia[Organism] AND cortex protein\n",
      "    Found: 1 retrieved / 1 total\n",
      "  Searching: Lepidoptera[Organism] AND cortex[Gene]\n",
      "    Found: 0 retrieved / 0 total\n",
      "\n",
      "Total unique cortex IDs: 1\n"
     ]
    }
   ],
   "source": [
    "def search_cortex_sequences(species, max_results=100):\n",
    "    \"\"\"Search for cortex gene sequences\"\"\"\n",
    "    \n",
    "    print(f\"\\nSearching for cortex sequences...\")\n",
    "    \n",
    "    search_terms = [\n",
    "        f\"{species}[Organism] AND cortex[Gene]\",\n",
    "        f\"{species}[Organism] AND cortex protein\",\n",
    "        \"Lepidoptera[Organism] AND cortex[Gene]\"  # Broader search\n",
    "    ]\n",
    "    \n",
    "    all_ids = set()\n",
    "    \n",
    "    for search_term in search_terms:\n",
    "        try:\n",
    "            print(f\"  Searching: {search_term}\")\n",
    "            \n",
    "            handle = Entrez.esearch(\n",
    "                db=Config.NCBI_DATABASE,\n",
    "                term=search_term,\n",
    "                retmax=max_results//2,\n",
    "                sort=\"relevance\"\n",
    "            )\n",
    "            \n",
    "            results = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            \n",
    "            ids = results[\"IdList\"]\n",
    "            total = int(results[\"Count\"])\n",
    "            \n",
    "            all_ids.update(ids)\n",
    "            print(f\"    Found: {len(ids)} retrieved / {total} total\")\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Search failed: {e}\")\n",
    "    \n",
    "    final_ids = list(all_ids)[:max_results]\n",
    "    print(f\"\\nTotal unique cortex IDs: {len(final_ids)}\")\n",
    "    \n",
    "    return final_ids\n",
    "\n",
    "# Search for cortex sequences\n",
    "cortex_ids = search_cortex_sequences(\n",
    "    species=Config.TARGET_SPECIES,\n",
    "    max_results=CortexConfig.MAX_SEQUENCES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89066100",
   "metadata": {},
   "source": [
    "SEQUENCE FETCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f984e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching 1 cortex sequences...\n",
      "Batch 1/1 - 1 sequences\n",
      "  Retrieved 1 records\n",
      "Total cortex records fetched: 1\n"
     ]
    }
   ],
   "source": [
    "def fetch_cortex_sequences(id_list, batch_size=5):\n",
    "    \"\"\"Fetch cortex sequences in batches\"\"\"\n",
    "    \n",
    "    if not id_list:\n",
    "        print(\"No IDs to fetch\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\nFetching {len(id_list)} cortex sequences...\")\n",
    "    \n",
    "    all_records = []\n",
    "    \n",
    "    for i in range(0, len(id_list), batch_size):\n",
    "        batch_ids = id_list[i:i+batch_size]\n",
    "        batch_num = (i // batch_size) + 1\n",
    "        total_batches = (len(id_list) + batch_size - 1) // batch_size\n",
    "        \n",
    "        print(f\"Batch {batch_num}/{total_batches} - {len(batch_ids)} sequences\")\n",
    "        \n",
    "        try:\n",
    "            handle = Entrez.efetch(\n",
    "                db=Config.NCBI_DATABASE,\n",
    "                id=batch_ids,\n",
    "                rettype=\"gb\",\n",
    "                retmode=\"text\"\n",
    "            )\n",
    "            \n",
    "            batch_records = list(SeqIO.parse(handle, \"genbank\"))\n",
    "            handle.close()\n",
    "            \n",
    "            all_records.extend(batch_records)\n",
    "            print(f\"  Retrieved {len(batch_records)} records\")\n",
    "            \n",
    "            time.sleep(1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Batch failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"Total cortex records fetched: {len(all_records)}\")\n",
    "    return all_records\n",
    "\n",
    "# Fetch cortex sequences\n",
    "cortex_records = fetch_cortex_sequences(cortex_ids, CortexConfig.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd26c11",
   "metadata": {},
   "source": [
    "DIRECT EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252f3c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single cortex sequence found - creating direct dataset...\n",
      "Cortex dataset created: 1 sequence, 1 haplotype\n",
      "Sequence length: 377523 bp\n",
      "GC content: 36.42%\n"
     ]
    }
   ],
   "source": [
    "def create_cortex_dataset_direct(records):\n",
    "    \"\"\"Create dataset directly from single cortex record\"\"\"\n",
    "    \n",
    "    if not records:\n",
    "        print(\"No cortex records to process\")\n",
    "        return pd.DataFrame(), []\n",
    "    \n",
    "    if len(records) == 1:\n",
    "        print(f\"\\nSingle cortex sequence found - creating direct dataset...\")\n",
    "        \n",
    "        record = records[0]\n",
    "        seq_str = str(record.seq).upper()\n",
    "        cleaned_seq = clean_sequence(seq_str)\n",
    "        \n",
    "        # Create single-row dataframe\n",
    "        data = {\n",
    "            'accession_id': record.id,\n",
    "            'description': record.description,\n",
    "            'organism': record.annotations.get('organism', 'Unknown'),\n",
    "            'sequence': cleaned_seq,\n",
    "            'sequence_length': len(cleaned_seq),\n",
    "            'gene_type': 'cortex',\n",
    "            'haplotype_id': 'Cortex_Hap_001'\n",
    "        }\n",
    "        \n",
    "        # Extract source information\n",
    "        for feature in record.features:\n",
    "            if feature.type == \"source\":\n",
    "                qualifiers = feature.qualifiers\n",
    "                data['country'] = qualifiers.get('country', ['Unknown'])[0]\n",
    "                data['collection_date'] = qualifiers.get('collection_date', ['Unknown'])[0]\n",
    "                data['collected_by'] = qualifiers.get('collected_by', ['Unknown'])[0]\n",
    "                break\n",
    "        \n",
    "        # Calculate GC content\n",
    "        gc_count = cleaned_seq.count('G') + cleaned_seq.count('C')\n",
    "        data['gc_content'] = round((gc_count / len(cleaned_seq)) * 100, 2)\n",
    "        \n",
    "        df = pd.DataFrame([data])\n",
    "        \n",
    "        # Create single haplotype group\n",
    "        haplotype_groups = [{\n",
    "            'haplotype_id': 'Cortex_Hap_001',\n",
    "            'representative_sequence': cleaned_seq,\n",
    "            'sequence_count': 1,\n",
    "            'frequency': 1.0\n",
    "        }]\n",
    "        \n",
    "        print(f\"Cortex dataset created: 1 sequence, 1 haplotype\")\n",
    "        print(f\"Sequence length: {len(cleaned_seq)} bp\")\n",
    "        print(f\"GC content: {data['gc_content']}%\")\n",
    "        \n",
    "        return df, haplotype_groups\n",
    "    \n",
    "    else:\n",
    "        # Fallback to normal processing if multiple sequences\n",
    "        print(f\"Multiple sequences found - using standard processing...\")\n",
    "        return pd.DataFrame(), []\n",
    "\n",
    "# Create cortex dataset directly\n",
    "cortex_final_df, cortex_haplotype_groups = create_cortex_dataset_direct(cortex_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e6b3e7",
   "metadata": {},
   "source": [
    "EXPORT FINAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa57da49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cortex dataset exported: ../data/final/biston_betularia_cortex_dataset_20250611_110102.csv\n",
      "Records: 1\n",
      "Columns: ['accession_id', 'description', 'organism', 'sequence', 'sequence_length', 'gene_type', 'haplotype_id', 'country', 'collection_date', 'collected_by', 'gc_content']\n",
      "Cortex haplotype summary exported: ../data/final/cortex_haplotype_summary_20250611_110102.csv\n",
      "Processing summary exported: ../data/final/cortex_processing_summary_20250611_110102.json\n"
     ]
    }
   ],
   "source": [
    "def export_cortex_dataset(df, haplotype_groups):\n",
    "    \"\"\"Export final cortex dataset\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No cortex data to export\")\n",
    "        return\n",
    "    \n",
    "    # Create final directory\n",
    "    os.makedirs(\"../data/final\", exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    # Export main dataset\n",
    "    dataset_file = f\"../data/final/biston_betularia_cortex_dataset_{timestamp}.csv\"\n",
    "    df.to_csv(dataset_file, index=False)\n",
    "    print(f\"\\nCortex dataset exported: {dataset_file}\")\n",
    "    print(f\"Records: {len(df)}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Export haplotype summary\n",
    "    if haplotype_groups:\n",
    "        haplotype_file = f\"../data/final/cortex_haplotype_summary_{timestamp}.csv\"\n",
    "        haplotype_df = pd.DataFrame(haplotype_groups)\n",
    "        haplotype_df.to_csv(haplotype_file, index=False)\n",
    "        print(f\"Cortex haplotype summary exported: {haplotype_file}\")\n",
    "    \n",
    "    # Export processing summary\n",
    "    summary = {\n",
    "        'processing_date': datetime.now().isoformat(),\n",
    "        'gene_type': 'cortex',\n",
    "        'target_species': Config.TARGET_SPECIES,\n",
    "        'sequences_found': len(cortex_ids) if cortex_ids else 0,\n",
    "        'sequences_processed': len(df),\n",
    "        'unique_haplotypes': len(haplotype_groups),\n",
    "        'mean_sequence_length': df['sequence_length'].mean(),\n",
    "        'mean_gc_content': df['gc_content'].mean()\n",
    "    }\n",
    "    \n",
    "    summary_file = f\"../data/final/cortex_processing_summary_{timestamp}.json\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Processing summary exported: {summary_file}\")\n",
    "\n",
    "# Export cortex dataset\n",
    "export_cortex_dataset(cortex_final_df, cortex_haplotype_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
